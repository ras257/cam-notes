\documentclass[../main.tex]{subfiles}
\begin{document}
\chapter{Fundamentals of Probability}
\section{Probability Spaces}
\subsection{Definitions}
\begin{definition}[Subset Complement]
  For any subset $A \subseteq \Omega$, the \textit{complement} of $A$ is defined as $A^{\comp} = \Omega \setminus A$.
\end{definition}
\begin{definition}[$\sigma$-algebra]
  Suppose $\Omega$ is a set and $\salg$ is a collection of subsets of $\Omega$.

  We call $\salg$ a \textit{$\sigma$-algebra} if:
  \begin{enumerate}
    \item $\Omega \in \salg$.
    \item If $A \in \salg$, then $A^{\comp} \in \salg$.
    \item If $(A_n)_{n \in \N}$ is a countable collection of sets in $\salg$ (i.e. $A_n \in \salg\ \forall n$), then their union $\bigcup_{n \in \N} A_n \in \salg$.
  \end{enumerate}
\end{definition}
\begin{definition}[Probability Measure]
  Consider a $\sigma$-algebra $\salg$ on $\Omega$.
  A function $\P: \salg \to [0, 1]$ is called a \textit{probability measure} if:
  \begin{enumerate}
    \item $\P(\Omega) = 1$
    \item For any countable disjoint collection $(A_n)_{n \in \N}$ in $\salg$:
      \[
        \P\left(\bigcup_{n} A_n\right) = \sum_{n} \P(A_n)
      \]
      This is known as \textit{countable additivity}
  \end{enumerate}
  $\P(A)$ is then called the \textit{probability} of $A \in \salg$.
\end{definition}
\begin{definition}[Probability Space]
  For a set $\Omega$, $\sigma$-algebra $\salg$ and probability measure $\P$, we call the triplet $(\Omega, \salg, \P)$ a \textit{probability space}.
\end{definition}
\begin{definition}[Outcomes and Events]
  The elements of $\Omega$ are called \textit{outcomes} and the elements of $\salg$ are called \textit{events}.
\end{definition}
We talk about probabilities of events and \textbf{not} probabilities of outcomes.
\begin{remark}
  When $\Omega$ is countable, we take $\salg$ to be all subsets of $\Omega$, that is, $\salg = \powerset{\Omega}$.
\end{remark}
\subsection{Properties of Probability Measures}
We can derive some basic properties about probability measures directly from the definitions:
\begin{enumerate}
  \item $\P(A^{\comp}) = 1 - \P(A)$ as $\P(A \cup A^{\comp}) = \P(\Omega) = 1 = \P(A) + \P(A^{\comp})$.
  \item $\P(\emptyset) = 0$ as the probability of an empty union is an empty sum.
  \item If $A \subseteq B$, then $\P(B \setminus A) = \P(B) - \P(A)$ as $\P((B \setminus A) \cup A) = \P(B \setminus A) + \P(A) = \P(B)$.
  \item If $A \subseteq B$, then $\P(A) \leq \P(B)$ as $\P(B \setminus A) \geq 0$ above.
  \item $\P(A \cup B) = \P(A) + \P(B) - \P(A \cap B)$ as:
    \begin{align*}
      \P(A \cup B) &= \P((A \setminus (A \cap B)) \cup (B \setminus (A \cap B)) \cup (A \cap B)) \\
                   &= \P(A \setminus (A \cap B)) + \P(B \setminus (A \cap B)) + \P(A \cap B) \\
                   &= \P(A) + \P(B) - \P(A \cap B)
    \end{align*}
\end{enumerate}
\begin{proposition}[Countable Subadditivity]
  If $(A_n)$ is a countable collection of events in $\salg$, then:
  \[
    \P\left(\bigcup_{n \in \N} A_n\right) \leq \sum_{n \in \N} \P(A_n)
  \]
  \label{countableSub}
\end{proposition}
\begin{proof}
  Define $B_1 = A_1$ and for $n \geq 2$ define:
  \[
    B_n = A_n \setminus (A_1 \cup \cdots \cup A_{n - 1})
  \]
  Consider $B_i$ and $B_j$ for $i \neq j$.
  WLOG, assume that $i < j$.
  $B_i \subseteq A_i$ as $B_i = A_i \setminus (\cdots)$ and $B_j \cap A_i = \emptyset$ as $i < j$ so $B_j$ has had all elements of $A_i$ removed from it.
  Thus $B_i \cap B_j = \emptyset$ for $i \neq j$ so $(B_n)$ is a disjoint collection of sets in $\salg$.
  Considering the union, we have:
  \begin{align*}
    \bigcup_{k = 1}^{n} B_k &= A_1 \cup (A_2 \setminus A_1) \cup (A_3 \setminus (A_1 \cup A_2)) \cup \cdots \cup( A_n \setminus (A_1 \cup \cdots \cup A_{n - 1})) \\
                            &= (A_1 \cup A_2) \cup (A_3 \setminus (A_1 \cup A_2)) \cup \cdots \cup (A_n \setminus (A_1 \cup \cdots \cup A_{n - 1})) \\
                            &\;\;\vdots \\
                            &= A_1 \cup A_2 \cup \cdots \cup A_n = \bigcup_{k = 1}^{n} A_k
  \end{align*}
  Thus $\bigcup\limits_{n \in \N} B_n = \bigcup\limits_{n \in \N} A_n$:
  \[
    \P\left(\bigcup_{n \in \N} A_n\right) = \P\left(\bigcup_{n \in \N} B_n\right) = \sum_{n \in \N} \P(B_n) \leq \sum_{n \in \N} \P(A_n)
  \]
  using countable additivity and $\P(B_n) \leq \P(A_n)$ as $B_n \subseteq A_n\ \forall n$.
\end{proof}
\subsection{Continuity of Probability Measures}
\begin{definition}[Increasing and Decreasing Sequences in $\salg$]
  A sequence of events $(A_n)_{n \in \N}$ in $\mathcal{F}$ is called:
  \begin{itemize}
    \item An \textit{increasing sequence of events} if $A_n \subseteq A_{n + 1}\ \forall n$
    \item A \textit{decreasing sequence of events} if $A_{n + 1} \subseteq A_n\ \forall n$
  \end{itemize}
\end{definition}
For an increasing sequence of events, $\P(A_n)$ is an increasing function of $n$ as $\P(A_n) \leq \P(A_{n + 1})\ \forall n$.
Similarly, for a decreasing sequence of events, $\P(A_n)$ is decreasing function of $n$ as $\P(A_{n + 1}) \leq \P(A_n)\ \forall n$.

We have a specific definition for continuity when considering probability measures:
\begin{proposition}[Continuity of Probability Measures]
  If $(A_n)$ is an increasing sequence of events in $\salg$, then:
  \[
    \P(A_n) \to \P\left(\bigcup_{k = 1}^{\infty} A_k\right) \text{ as $n \to \infty$}
  \]
\end{proposition}
\begin{proof}
  Similarly to in the proof of \cref{countableSub}, define $B_1 = A_1$, and, for $n \geq 2$ define:
  \[
    B_n = A_n \setminus (A_1 \cup \cdots \cup \cdots A_{n - 1})
  \]
  Then $(B_n)$ is disjoint collection of events and $\bigcup_{k = 1}^{n} A_k = \bigcup_{k = 1}^{n} B_k$.
  Since $A_n \subseteq A_{n + 1}\ \forall n$, $\bigcup_{k = 1}^{n} A_k = A_n$ so:
  \[
    \P(A_n) = \P\left(\bigcup_{k = 1}^{n} B_k\right) = \sum_{k = 1}^{n} \P(B_k) \to \sum_{k = 1}^{\infty} \P(B_k) \text{ as $n \to \infty$}
  \]
  We can then rewrite this infinite sum using countable additivity:
  \[
    \sum_{k = 1}^{\infty} \P(B_k) = \P\left(\bigcup_{k = 1}^{\infty} B_k\right)
  \]
  and since $\bigcup_{k = 1}^{\infty} B_k = \bigcup_{k = 1}^{\infty} A_k$:
  \[
    \P(A_n) \to \P\left(\bigcup_{k = 1}^{\infty} A_k\right)
  \]
  which is the desired result.
\end{proof}
\begin{corollary}
  If $(A_n)$ is a decreasing sequence of events in $\salg$, then:
  \[
    \P(A_n) \to \P\left(\bigcap_{k = 1}^{\infty} A_k\right) \text{ as $n \to \infty$}
  \]
\end{corollary}
\begin{proof}
  $(A_n)$ is a decreasing sequence of events so $A_{n + 1} \subseteq A_{n}\ \forall n \iff  A^{\comp}_{n} \subseteq A^{\comp}_{n + 1}\  \forall n$.
  Thus $(A^{\comp}_n)$ is an increasing sequence of events so we can apply the previous result.
  \begin{align*}
    \P(A^{\comp}_n) &\to \P\left(\bigcup_{k = 1}^{\infty} A^{\comp}_k\right) \\
    \implies 1 - \P(A_n) &\to 1 - \P\left(\left[\bigcup_{k = 1}^{\infty} A^{\comp}_k\right]^{\comp}\right) \\
    \implies \P(A_n) &\to \P\left(\left[\bigcup_{k = 1}^{\infty} A^{\comp}_k\right]^{\comp}\right)
  \end{align*}
  We can rewrite the complement of the union as the intersection of the complements:
  \begin{align*}
    \left[\bigcup_{k = 1}^{\infty} A^{\comp}_k\right]^{\comp} &= \Omega \setminus (A^{\comp}_1 \cup A^{\comp}_2 \cup \cdots) \\
                                                   &= (\Omega \setminus A^{\comp}_1) \cap (\Omega \setminus A^{\comp}_2) \cap \cdots \\
                                                   &= A_1 \cap A_2 \cap \cdots \\
                                                   &= \bigcap_{k = 1}^{\infty} A_k
  \end{align*}
  which is the desired result.
\end{proof}
\subsection{Examples of Probability Spaces}
We will now look at some basic examples of probability spaces.
\begin{example}[6-Sided Die]
  The set of outcomes is $\Omega = \{1, 2, 3, 4, 5, 6\}$, and as it is countable, $\salg = \powerset{\Omega}$.
  We then have $\P(\{\omega\}) = 1/6$ for $\omega \in \Omega$ as each singleton event is equally likely.
  Furthermore, for any $A \in \salg$, we have $\P(A) = |A|/6$.
\end{example}
\begin{example}[Picking Elements]
  For a set $\Omega$ with $n$ elements, $\Omega = \{\omega_1, \ldots, \omega_n\}$, $\salg = \powerset{\Omega}$.
  We can model the experiment of picking a random element of $\Omega$ by setting $\P(A) = |A|/|\Omega|$.
  We then have:
  \[
    \P(\{\omega\}) = 1/|\Omega|\ \forall \omega \in \Omega
  \]
\end{example}
\begin{example}[Picking Balls]
  Suppose we have $n$ balls labelled $\{1, \ldots, n\}$ that are indistinguishable by touch.
  If we wish to model picking $k \leq n$ balls \textbf{at random} without replacement then:
  \[
    \Omega = \{A \subseteq \{1, \ldots, n\}: |A| = k\},\ |\Omega| = \binom{n}{k},\ \P(\{\omega\}) = \frac{1}{\binom{n}{k}}
  \]
\end{example}
\begin{example}[Deck of Cards]
  Take a standard deck of 52 cards that is \textbf{well-shuffled} (all permutations equally likely).
  The set of outcomes $\Omega$ is then:
  \[
    \Omega = \{\text{all permutations of 52 cards}\},\ |\Omega| = 52!
  \]
  We can then find the probability that the top two cards are aces:
  \[
    \P(\text{top 2 cards are aces}) = \frac{4 \times 3 \times 50!}{52!}
  \]
  As there are 4 ways to pick the top ace, 3 ways to pick the second ace, and $50!$ ways to pick the remaining cards.
\end{example}
\begin{example}[Largest Digit]
  Consider a string of $n$ random digits from $\{0, \ldots, 9\}$.
  The set of outcomes is then:
  \[
    \Omega = \{0, \ldots, 9\}^n,\ |\Omega| = 10^n
  \]
  We can then define the even $A_k$ to be:
  \[
    A_k = \{\text{no digit exceeds $k$}\}
  \]
  then
  \[
    \P(A_k) = \frac{(k + 1)^n}{10^n}
  \]
  as we pick from $k + 1$ possible digits $n$ times.

  Furthermore, if $B_k = \{\text{largest digit is $k$}\}$, we have:
  \[
    \P(B_k) = \P(A_k \setminus A_{k - 1}) = \frac{(k + 1)^n - k^n}{10^n}
  \]
  as $A_{k - 1} \subseteq A_k$.
\end{example}
\begin{example}[Birthday Problem]
  Suppose we have $n$ people, what is the probability that at least two of them share the same birthday?
  We first assume each birthday is equally likely to be one of $\{1, \ldots, 365\}$ (i.e. no-one was born on the 29th of February).

  The set of outcomes and $\sigma$-algebra is:
  \[
    \Omega = \{1, 2, \ldots, 365\}^n,\ \salg = \powerset{\Omega}
  \]
  Since each birthday is equally likely, the probability of a singleton event is:
  \[
    \P(\{\omega\}) = \frac{1}{365^{n}},\ \omega \in \Omega
  \]
  We then define the event $A = \{\text{at least two people have same birthday}\}$.
  It is often more convenient to work out $\P(A^{\comp})$ and then use this to find $\P(A)$.
  The compliment of $A$ is the event that no-one shares a birthday:
  \[
    A^{\comp} = \{\text{all $n$ birthdays are distinct}\}
  \]
  We can then calculate $\P(A^{\comp})$ as:
  \[
    \P(A^{\comp}) = \frac{365 \times 364 \times \cdots \times (365 - n + 1)}{365^n}
  \]
  so
  \[
    \P(A) = 1 - \P(A^{\comp}) = 1 - \frac{365 \times 364 \times \cdots \times (365 - n + 1)}{365^n}
  \]

  Surprisingly, for $n = 22$, $\P(A) \approx 0.476$, and for $n = 23$, $\P(A) \approx 0.507$.
  This means that we only need 23 people for the probability of two people sharing a birthday to be greater than $1/2$.
\end{example}
\subsection{Principle of Inclusion Exclusion}
We saw that for two sets $A, B$, $\P(A \cup B) = \P(A) + \P(B) - \P(A \cap B)$.
We can apply this result three times to extend it to three sets $A, B, C$:
\begin{align*}
  \P(A \cup B \cup C) &= \P(A \cup B) + \P(C) - \P((A \cup B) \cap C) \\
                      &= \P(A) + \P(B) + \P(C) - \P(A \cap B) - \P((A \cap C) \cup (B \cap C)) \\
                      &= \P(A) + \P(B) + \P(C) - \P(A \cap B) - \P(A \cap C) - \P (B \cap C) \\
                      &\quad + \P((A \cap C) \cap (B \cap C)) \\
                      &= \P(A) + \P(B) + \P(C) - \P(A \cap B) - \P(A \cap C) - \P(B \cap C) + \P(A \cap B \cap C)
\end{align*}
We can also use induction to extend this to the \textit{principle of inclusion exclusion}.
\begin{proposition}[Inclusion-Exclusion Formula]
  For $A_1, \ldots, A_n \in \salg$:
  \[
    \P\left(\bigcup_{i = 1}^{n} A_i\right) = \sum_{k = 1}^{n} (-1)^{k + 1} \sum_{1 \leq i_1 < \ldots < i_k \leq n} \P(A_{i_1} \cap \cdots \cap A_{i_k})
  \]
  \label{inclusionExclusion}
\end{proposition}
\begin{proof}
  \induction
  {$n = 2$}{
    $\P(A \cup B) = \P(A) + \P(B) - \P(A \cap B)$ as shown previously.
  }
  {$n - 1$ events}{}
  {$n$ events}{
    \begin{align*}
      \P\left(\bigcup_{i = 1}^{n}  A_i\right) &= \P\left(\left[\bigcup_{i = 1}^{n - 1} A_i\right] \cup A_n\right) \\
                                   &= \P\left(\bigcup_{i = 1}^{n - 1} A_i\right) + \P(A_n) - \P\left(\bigcup_{i = 1}^{n - 1} \underbrace{(A_i \cap A_n)}_{B_i}\right) \tag{$\dag$} \label{eqnDag}
    \end{align*}
    Let $B_i = A_i \cap A_n$.
    Applying the induction hypothesis:
    \[
      \P\left(\bigcup_{i = 1}^{n - 1} A_i\right) = \sum_{k = 1}^{n - 1} (-1)^{k + 1} \sum_{1 \leq i_1 < \ldots < i_k \leq n - 1} \P(A_{i_1} \cap \cdots \cap A_{i_k}) \tag{$\star$} \label{eqnStar}
    \]
    \begin{align*}
      \P\left(\bigcup_{i = 1}^{n - 1} B_i\right) &= \sum_{k = 1}^{n - 1} (-1)^{k + 1} \sum_{1 \leq i_1 < \cdots <i_k \leq n - 1} \P(B_{i_1}\cap \cdots \cap B_{i_k}) \\
                                                 &= \sum_{k = 1}^{n - 1} (-1)^{k + 1} \sum_{1 \leq i_1 < \cdots <i_k \leq n - 1} \P(A_{i_1}\cap \cdots \cap A_{i_k} \cap A_n) \tag{$\ast$} \label{eqnAst}
    \end{align*}
    Combining the above into \cref{eqnDag}, the $\P(A_n)$ accounts for the additional single intersection when $k = 1$ in \cref{eqnStar} and \cref{eqnAst} accounts for all of the intersections that include the new event $A_n$.
    The additional minus sign accounts for the fact that the terms of \cref{eqnAst} have an additional intersection so their signs need to be flipped to achieve the final result.
  }
\end{proof}
If we have the probability space $(\Omega, \salg, \P)$ for finite $\Omega$ and define $\P(A) = |A|/|\Omega|$, then we can derive the set-theoretic version of inclusion exclusion that we saw in IA Numbers and Sets:
\[
  |A_1 \cup \cdots \cup A_n| = \sum_{k = 1}^{n} (-1)^{k + 1} \sum_{1 \leq i_1 < \cdots < i_k \leq n} |A_{i_1} \cap \cdots \cap A_{i_k}|
\]
\subsubsection{Boferroni Inequalities}
Using the principle of inclusion exclusion in the cases of two and three sets, we see that:
\begin{align*}
  \P(A \cup B) &\leq \P(A) + \P(B) \\
  \P(A \cup B \cup C) &\geq \P(A) + \P(B) + \P(C) - \P(A \cap B) - \P(A \cap C) - \P(B \cap C) \\
\end{align*}
The \textit{Bofferoni Inequalities} tell us if the truncation of the inclusion exclusion formula will be an overestimate or an underestimate based on if it finishes on an even or odd term.
\begin{proposition}[Bofferoni Inequalities]
  \[
    \P\left(\bigcup_{i = 1}^{n} A_i\right) \begin{cases}
    \leq \sum\limits_{k = 1}^{r} (-1)^{k + 1} \sum\limits_{1 \leq i_1 < \cdots < i_k \leq n} \P(A_i \cap \cdots \cap A_{i_k}) & \text{ if $r$ is odd} \\

    \geq \sum\limits_{k = 1}^{r} (-1)^{k + 1} \sum\limits_{1 \leq i_1 < \cdots < i_k \leq n} \P(A_i \cap \cdots \cap A_{i_k}) & \text{ if $r$ is even} \\
    \end{cases}
  \]
\end{proposition}
\begin{proof}
  \induction
  {$n = 2$}{
    For $r = 1$, $\P(A) + \P(B) \geq \P(A) + \P(B) - \P(A \cap B) = \P(A \cup B)$.\par
    For $r = 2$, $\P(A) + \P(B) - \P(A \cap B) \leq \P(A \cup B)$, which are the correct inequalities.
  }
  {$n - 1$ events}{}
  {$n$ events}{
    Assume $r$ is odd.
    \begin{align*}
      \P\left(\bigcup_{i = 1}^{n} A_i\right) &= \P\left(\left[\bigcup_{i = 1}^{n - 1} A_i\right] \cup A_n\right) \\
                                             &= \P\left(\bigcup_{i = 1}^{n - 1} A_i\right) + \P(A_n) - \P\left(\bigcup_{i = 1}^{n - 1} B_i\right) \tag{$\star$} \label{eqnStar2}
    \end{align*}
    where $B_i = A_i \cap A_n$.
    By the induction hypothesis, since $r$ is odd:
    \[
      \P\left(\bigcup_{i = 1}^{n - 1} A_i\right) \leq \sum_{k = 1}^{r} (-1)^{k + 1} \sum_{1 \leq i_1 < \cdots < i_k \leq n - 1} \P(A_i \cap \cdots \cap A_{i_k})
    \]
    Since $r$ is odd $r - 1$ is even, using the induction hypothesis again:
    \begin{align*}
      \P\left(\bigcup_{i = 1}^{n - 1} B_i\right) &\geq \sum_{k = 1}^{r - 1} (-1)^{k + 1} \sum_{1 \leq i_1 < \cdots < i_k \leq n - 1} \P(B_{i_n} \cap \cdots \cap B_{i_k}) \\
                                                 &= \sum_{k = 1}^{r - 1} (-1)^{k + 1} \sum_{1 \leq i_1 < \cdots < i_k \leq n - 1} \P(A_{i_n} \cap \cdots \cap A_{i_k} \cap A_n)
    \end{align*}
    Substituting back into \cref{eqnStar2} yields the desired result.
    The proof for even $r$ is identical apart from the two inequalities above are flipped so the final inequality will also be flipped, giving the result for even $r$.
  }
\end{proof}
\section{Combinatorial Analysis}
\subsection{Multinomial Coefficients}
Suppose $\Omega$ is a finite set with $|\Omega| = n$.
We want to partition $\Omega$ into $k$ disjoint subsets $\Omega_1, \ldots, \Omega_k$ with $|\Omega_i| = n_i$ and $n_1 + \cdots + n_k = n$.
How many ways are there to do this?
Let $M$ be the number of ways:
\begin{align*}
  M &= \binom{n}{n_1} \times \binom{n - n_1}{n_2} \times \cdots \times \binom{n - (n_1 + \cdots n_{k - 1})}{n_k} \\
    &= \frac{n!}{n_1! n_2! \cdots n_k!}
\end{align*}
As we pick $n_1$ from $n$, $n_2$ from the remaining $n - n_1$, and so on.
\begin{definition}[Multinomial Coefficient]
  For $n_1, \ldots, n_k$ such that $n_1 + \cdots + n_k = n$, we define the multinomial coefficient to be:
  \[
    \binom{n}{n_1, n_2, \ldots, n_k} = \frac{n!}{n_1! n_2! \cdots n_k!}
  \]
\end{definition}
\subsection{Increasing Functions}
\begin{definition}[Increasing and Strictly Increasing Functions]
  A function $f$ is:
  \begin{itemize}
    \item \textit{Increasing} if $x < y \implies f(x) \leq f(y)$
    \item \textit{Strictly increasing} if $x < y \implies f(x) < f(y)$
  \end{itemize}
\end{definition}
\begin{proposition}
  For $k \leq n$, the number of \textbf{strictly increasing} $f: \{1, \ldots, k\} \to \{1, \ldots, n\}$ is $\binom{n}{k}$
  \label{strictlyIncreasingF}
\end{proposition}
\begin{proof}
  If we pick a subset of size $k$ from $\{1, \ldots, n\}$ to be $\im f$, then this uniquely determines $f$ as it must be order preserving.
  Therefore, the number of strictly increasing $f$ is the number of such subsets which is $\binom{n}{k}$.
\end{proof}
\begin{proposition}
  For $k \leq n$, the number of \textbf{increasing} $f: \{1, \ldots, k\} \to \{1, \ldots, n\}$ is $\binom{n + k - 1}{k}$.
\end{proposition}
\begin{proof}
  We can define a bijection between:
  \begin{align*}
    &\{f: \{1, \ldots, k\} \to \{1, \ldots, n\} \text{ increasing}\} \\
    \text{ and }&\{g: \{1, \ldots, k\} \to \{1, \ldots, n + k - 1\} \text{ strictly increasing}\}
  \end{align*}
  We do this by mapping each increasing $f: \{1, \ldots, k\} \to \{1, \ldots, n\}$ to $g(i) = f(i) + i - 1$.
  Such $g$ are strictly increasing as, if $i < j$, then $f(i) - f(j) \leq 0$ and $i - j < 0$ so:
  \[
    g(i) - g(j) = (f(i) - f(j)) + (i - j) < 0 \implies g(i) < g(j)
  \]
  This construction ensures that $g(1) = f(1)$ and then always adds 1 each time the input increases to ensure that $g$ never stays at a constant value.

  This mapping is a bijection as:
  \[
    g_1 = g_2 \implies f_1(i) + i - 1 = f_2(i) + i - 1\ \forall i \implies f_1(i) = f_2(i)\ \forall i \implies f_1 = f_2
  \]
  Thus, the number of increasing $f$ is the same as the number of strictly increasing $g: \{1, \ldots, k\} \to \{1, \ldots, n + k - 1\}$, which is $\binom{n + k - 1}{k}$ by \cref{strictlyIncreasingF}.
\end{proof}
\subsection{Surjective Functions}
\begin{proposition}
  For $n \geq m$, the number of surjective $f: \{1, \ldots, n\} \to \{1, \ldots, m\}$ is:
  \[
    |A| = \sum_{k = 0}^{m} (-1)^{k} \binom{m}{k} (m - k)^{n}
  \]
\end{proposition}
\begin{proof}
  Consider $\Omega = \{f: \{1, \ldots, n\} \to \{1, \ldots, m\}\}$ and $A = \{f \in \Omega: f \text{ is a surjection}\}$.
  Define:
  \[
    A_i = \{f \in \Omega: i \notin \{f(1), \ldots, f(n)\}\} \text{ for } i \in \{1, \ldots, m\}
  \]
  We can then derive the following chain of equivalence:
  \begin{align*}
    f \in A &\iff f \text{ is surjective} \\
            &\iff \forall i \in \{1, \ldots, m\}, \exists j \in \{1, \ldots, n\} \text{ s.t. } f(j) = i \\
            &\iff \centernot\exists i \in \{1, \ldots, m\} \text{ s.t. } \forall j \in \{1, \ldots, n\},\ f(j) \neq i \\
            &\iff f \notin A_i\ \forall i \in \{1, \ldots, m\} \\
            &\iff f \in A^{\comp}_i\ \forall i \in \{1, \ldots, m\} \\
            &\iff f \in A^{\comp}_1 \cap \cdots \cap A^{\comp}_m
  \end{align*}
  Thus $A = A^{\comp}_1 \cap \cdots \cap A^{\comp}_m = (A_1 \cup \cdots \cup A_m)^{\comp}$ so $|A| = |\Omega| - |A_1 \cup \cdots \cup A_m|$.
  $|\Omega| = m^{n}$ as this is the total number of functions $f: \{1, \ldots, n\} \to \{1, \ldots, m\}$.
  Using inclusion exclusion (\cref{inclusionExclusion}), we have:
  \[
    |A_1 \cup \cdots \cup A_m| = \sum_{k = 1}^{m} (-1)^{k + 1} \sum_{1 \leq i_1 < \cdots < i_k \leq n} |A_{i_1} \cap \cdots \cap A_{i_k}|
  \]
  $A_{i_1} \cap \cdots \cap A_{i_k}$ are all the functions in $\Omega$ that do not contain $i_1, \ldots, i_k$ in their image.
  There are $(m - k)^{n}$ such functions as we are essentially counting the number of $g: \{1, \ldots, n\} \to \{1, \ldots, m - k\}$.
  As there are $\binom{m}{k}$ ways to choose a subset $\{i_1, \ldots, i_k\}$ from $\{1, \ldots, m\}$:
  \[
    |A_1 \cup \cdots \cup A_m| = \sum_{k = 1}^{m} (-1)^{k + 1} \binom{m}{k}(m - k)^{n}
  \]
  Therefore:
  \begin{align*}
    |A| &= m^{n} - \sum_{k = 1}^{m} (-1)^{k + 1} \binom{m}{k}(m - k)^{n} \\
        &= \sum_{k = 0}^{m} (-1)^{k} \binom{m}{k} (m - k)^{n}
  \end{align*}
\end{proof}
\subsection{Stirling's Formula}
\begin{remark}[Asymptotic Notation]
  If $(a_n)$ and $(b_n)$ are sequences then we write $a_n \sim b_n$ as $n \to \infty$ if $\frac{a_n}{b_n} \to 1$ as $n \to \infty$.
\end{remark}
Stirling's formula provides an asymptotic expression for $n!$ as $n \to \infty$.
\begin{theorem}[Stirling's Formula]
  \[
    n! \sim \sqrt{2\pi n} \left(\frac{n}{e}\right)^n \text{ as $n \to \infty$}
  \]
  \label{stirling}
\end{theorem}
We will first show the weaker statement $\log n! \sim n \log n$.
\begin{proof}[Weaker Statment]
  Define $\ell_n = \log n! = \log 2 + \cdots + \log n$ and for $x \in \R$, we write $\floor{x}$ to mean the integer part of $x$.
  \[
    \log \floor{x} \leq \log x \leq \log \floor{x + 1}
  \]
  If we integrate this from $1$ to $n$ we get:
  \begin{align*}
    \sum_{k = 1}^{n - 1} \log k &\leq \int_{1}^{n} \log x \d{x} \leq \sum_{k = 1}^{n} \log k \\
    \ell_{n - 1} &\leq n \log n - n + 1 \leq \ell_{n}
\end{align*}
So we can bound $\ell_n$ by:
\[
  n \log n - n + 1 \leq \ell_n \leq (n + 1) \log(n + 1) - (n + 1) + 1
\]
we can then divide through by $n \log n$ to get:
\[
  1 - \cancelto{0}{\frac{n - 1}{n \log n}} \leq \frac{\ell_n}{n \log n} \leq \cancelto{1}{\frac{\log (n + 1)}{\log n}} + \cancelto{0}{\frac{\log(n + 1)}{n \log n}} - \cancelto{0}{\frac{1}{\log n}}
\]
as $n \to \infty$, so by squeeze theorem:
\[
  \frac{\ell_n}{n \log n} \to 1 \text{ as $n \to \infty$}
\]
and thus $\ell_n = \log n! \sim n \log n$.
\end{proof}
\nonexaminable
To prove the stronger Stirling's formula, we first need to prove an integral identity.
\begin{lemma}
  For all twice differentiable $f : \R \to \R$ and $a < b$ we have:
  \label{integralIdentity}
  \[
    \int_{a}^{b} f(x)\d{x} = \frac{f(a) + f(b)}{2}(b - a) - \frac{1}{2}\int_{a}^{b} (x - a)(b - x)f''(x) \d{x}
  \]
\end{lemma}
\begin{proof}
  Integrating the final integral by parts twice yields:
  \begin{align*}
    \int_{a}^{b} (x - a)(b - x) f''(x) \d{x} &= \eval{(-x^2 + ax + bx - ab)f'(x)}{a}{b} + \int_{a}^{b} (2x - a - b)f'(x) \d{x} \\
                                             &= \int_{a}^{b} (2x - a - b)f'(x) \d{x} \\
                                             &= \eval{(2x - a - b)f(x)}{a}{b} - 2 \int_{a}^{b} f(x) \d{x} \\
                                             &= (b - a)(f(b) + f(a)) - 2 \int_{a}^{b} f(x) \d{x}
  \end{align*}
  from which the identity follows.
\end{proof}
We can now prove the stronger asymptotic expression:
\begin{proof}[Stirling's Formula -- \Cref{stirling}]\par
  \textbf{Showing $n! \sim n^n e^{-n}\sqrt{n} \cdot A$}\par
  Taking $f(x) = \log x$, $a = k$, $b = k + 1$ for $k \in \N$ in \cref{integralIdentity} yields:
  \[
    \int_{k}^{k + 1} \log x \d{x} = \frac{\log k + \log(k + 1)}{2} + \frac{1}{2}\int_{k}^{k + 1} \frac{(x - k)(k + 1 - x)}{x^2} \d{x}
  \]
  Summing both sides from $k = 1$ to $n - 1$, we have:
  \[
    \int_{1}^{n} \log x \d{x} = \frac{\log (n - 1)! + \log n!}{2} + \sum_{k = 1}^{n - 1} a_k
  \]
  where
  \[
    a_k = \frac{1}{2} \int_{k}^{k + 1} \frac{(x - k)(k + 1 - x)}{x^2} \d{x} \stackrel{x \mapsto x + k}= \frac{1}{2} \int_{0}^{1} \frac{x(1 - x)}{(x + k)^2} \d{x}
  \]
  We can also rewrite:
  \[
    \frac{\log (n - 1)! + \log n!}{2} = \frac{\log n! - \log n + \log n!}{2} = \log n! - \frac{\log n}{2}
  \]
  and so, after rearranging:
  \begin{align*}
    \log n! &= n \log n - n + \frac{\log n}{2} + 1 - \sum_{k = 1}^{n - 1} a_k \\
    \implies n! &= n^n e^{-n} \sqrt{n} \exp\left[1 - \sum_{k = 1}^{n - 1} a_k\right]
  \end{align*}
  We now wish to bound $a_k$.
  Since $x + k \geq k$ for $x \geq 0$ we have:
  \begin{align*}
    a_k = \frac{1}{2} \int_{0}^{1} \frac{x(1 - x)}{(x + k)^2} \d{x} &\leq \frac{1}{2k^2} \int_{0}^{1} x(1 - x) \d{x} \\
                                                                    &= \frac{1}{12k^2}
  \end{align*}
  This means that $\sum_{k = 1}^{\infty} a_k$ converges by comparison to $\sum_{k = 1}^{\infty} \frac{1}{k^2}$.
  Let
  \[
    A = \exp\left[1 - \sum_{k = 1}^{\infty} a_k\right]
  \]
  So $n! = n^n e^{-n} \sqrt{n} \cdot A \exp\left[\sum_{k = n}^{\infty} a_k\right]$.
  As $n \to \infty$, $\sum_{k = n}^{\infty} a_k \to 0$ so $\exp\left[\sum_{k = n}^{\infty} a_k\right] \to 1$.
  Thus:
  \[
    \frac{n!}{n^{n}e^{-n}\sqrt{n}} \to A \text{ as $n \to \infty$}
  \]
  We now know that $n! \sim n^n e^{-n}\sqrt{n} \cdot A$ for some constant $A$.

  \textbf{Showing $A = \sqrt{2 \pi}$}\par
  To show that $A = \sqrt{2 \pi}$, we will find an asymptotic expression for $2^{-2n} \binom{2n}{n}$ in two different ways.

  Firstly, using the asymptotic expression we just derived, we have:
  \[
    2^{(-2n)}\binom{2n}{n} = 2^{-2n} \frac{(2n)!}{(n!)^2} \sim \frac{2^{-2n} (2n)^{2n} e^{-2n} \sqrt{2n} \cdot A}{(n^{n} e^{-n}\sqrt{n} \cdot A)(n^{n} e^{-n}\sqrt{n} \cdot A)} = \frac{\sqrt{2}}{A\sqrt{n}}
  \]

  Secondly, using a different method, we will show that $2^{-2n}\binom{2n}{n} \sim \frac{1}{\sqrt{\pi n}}$ as $n \to \infty$, which will then force $A = \sqrt{2\pi}$.

  \textbf{Showing $2^{-2n} \binom{2n}{n} \sim \frac{1}{\sqrt{\pi n}}$}\par
  Consider the integrals:
  \[
    I_n = \int_{0}^{\pi/2} (\cos \theta)^{n} \d{\theta},\ I_0 = \frac{\pi}{2},\  I_1 = 1
  \]
  Integrating by parts:
  \begin{align*}
    I_n &= \eval{\cos^{n - 1} \theta \sin \theta}{0}{\pi/2} + (n - 1)\int_{0}^{\pi/2} \cos^{n - 2} \theta \sin^2 \theta \d{\theta} \\
        &= (n - 1) \int_{0}^{\pi/2} \cos^{n - 2} \theta (1 - \cos^2 \theta) \d{\theta} \\
        &= (n - 1)(I_{n - 2} - I_n)
  \end{align*}
  Rearranging, we obtain the recurrence $I_n = \frac{n - 1}{n} I_{n - 2}$.
  Thus:
  \begin{align*}
    I_{2n} = \frac{2n - 1}{2n} I_{2n - 2} &= \frac{(2n - 1) \cdot (2n - 3) \cdots 3 \cdot 1}{2n \cdot (2n - 2) \cdots 2} I_0 \\
                                          &= \frac{2n \cdot (2n - 1) \cdot (2n - 2) \cdots 3 \cdot 2\cdot 1}{2n \cdot 2n \cdot (2n - 2) \cdot (2n - 2) \cdots 2 \cdot 2} I_0 \\
                                          &= \frac{(2n)!}{2^{2n} (n!)^2} I_0  \\
                                          &= 2^{-2n} \binom{2n}{n} \frac{\pi}{2}
  \end{align*}
  Similarly:
  \[
    I_{2n + 1} = \frac{(2n) \cdots 4 \cdot 2}{(2n + 1) \cdots 3\cdot 1} I_1 = \frac{1}{2n + 1} \left(2^{-2n} \binom{2n}{n}\right)^{-1}
  \]
  If we know that $\frac{I_{2n}}{I_{2n + 1}} \to 1$ as $n \to \infty$ then:
  \[
    \frac{\frac{\pi}{2} \cdot 2^{-2n} \cdot \binom{2n}{n}}{\frac{1}{2n + 1} \cdot \left(2^{-2n} \cdot \binom{2n}{n}\right)^{-1}} \to 1 \implies \left(2^{-2n} \cdot \binom{2n}{n}\right)^{2} \sim \frac{1}{\pi n} \text{ as $n \to \infty$}
  \]
  which is the desired result.

  Consider $\frac{I_n}{I_{n - 2}}$:
  \[
    \frac{I_n}{I_{n - 2}} = \frac{n - 1}{n} \to 1 \text{ as $n \to \infty$}
  \]
  $I_n$ is decreasing in $n$ as the integrand is $0 \leq \cos \theta \leq 1$ over the integration bounds, so:
  \[
    \frac{I_{2n}}{I_{2n + 1}} \leq \frac{I_{2n - 1}}{I_{2n + 1}} \to 1 \text{ and } \frac{I_{2n}}{I_{2n + 1}} \geq \frac{I_{2n}}{I_{2n - 2}} \to 1
  \]
  So $\frac{I_{2n}}{I_{2n + 1}} \to 1$ by squeeze theorem as $n \to \infty$.

  \textbf{Conclusion}\par
  This forces $A = \sqrt{2\pi}$ and so $n! \sim \sqrt{2\pi n} \left(\frac{n}{e}\right)^{n}$.
\end{proof}
\end{document}
