\documentclass[../main.tex]{subfiles}
\begin{document}
\chapter{Basic Calculus}
\section{Introduction}
Differential equations appear in almost all branches of science and applied mathematics.
\begin{example}[Newton's Second Law]
  \[
    \underbrace{m}_{\text{Mass}} \ddot{x} = \underbrace{F(x, t)}_{\text{Force}}
  \]
  This equation relates the rate of change of position $x$, the \textit{dependant variable}, with time $t$, the \textit{independent variable}.
\end{example}
\section{Differentiation}
\begin{definition}[Derivative]
  The \textit{derivative} of a function $f(x)$ with respect to its argument $x$ is defined as:
  \[
    \deriv{f}{x} = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}
  \]
\end{definition}
\begin{remark}[Notation]
  We sometimes also use the notation $f'(x)$ or $\dot{f}(x)$ (The dot notation is usually used when $f$ is a function  of time).
\end{remark}
The derivative of a function allows us to determine the gradient of a function at a particular point.
% Maybe add plot?
\begin{definition}[Informal Definition of a Limit]
  Informally, if $\lim_{x \to x_0} f(x) = A$ then $f(x)$ can be made arbitrarily close to $A$ by making $x$ sufficiently close to $x_0$.
  (Note that we don't require that $f(x_0) = A$).
  This is explored further in Analysis I.
\end{definition}
\begin{remark}[Note]
  For the derivative to exist we require both the left and right-handed limits to exist and be equal.
  \[
    \lim_{h \to 0^-} \text{ and } \lim_{h \to 0^+} \text{ exist and are equal}
  \]
\end{remark}
\begin{example}
  Consider $f(x) = |x|$ so
  \[
    \at{\deriv{f}{x}}{0} = \lim_{h \to 0} \frac{|h|}{h}
  \]
  But note that the left and right-handed limits are different ($-1$ and $1$) so $f$ is \textbf{not} differentiable at $x = 0$ but is everywhere else.
\end{example}
We can define higher order derivatives for sufficiently smooth functions:
\[
  \deriv{}{x}\left(\deriv{f}{x}\right) = \deriv[2]{f}{x} = f''(x) = \ddot{f}(x)
\]
\begin{remark}[Notation]
  For the $n$th derivative we use the notation:
  \[
    \deriv[n]{f}{x} = f^{(n)}(x) 
  \]
\end{remark}
\subsection{Order Parameters}
Order parameters allow us to compare the behaviour of functions close to a limiting point, usually denoted $x_0$.
\begin{definition}[Big-$O$ Notation]
  \begin{proofcases}
    \begin{case}{$x_0$ finite}
      $f(x)$ is $O(g(x))$ as $x \to x_0$ if $\exists \delta > 0 \text{ and } M > 0$ such that $\forall x$ with $0 < |x - x_0| < \delta$, then $|f(x)| \leq M |g(x)|$.
    \end{case}
    \begin{case}{$x_0$ infinite}
      $f(x)$ is $O(g(x))$ as $x \to \infty$ if $\exists x_1 > 0 \text{ and } M > 0 \text{ such that } \forall x > x_1$, then $|f(x)| \leq M|g(x)|$.
    \end{case}
  \end{proofcases}
\end{definition}
From the definition it follows that if $f(x)$ is $O(g(x))$ then $f(x)/g(x)$ is bounded by $M$ as $x \to x_0$.
\begin{remark}[Notation]
This is often written $f(x) = O(g(x))$ although note that the use of the equals sign is an abuse of notation.
This is because $O(g(x))$ is a \textit{class} of functions but in practice using equals is simply more convenient.
\end{remark}
\begin{example}
  As $x \to 0$, $x^2 = O(x)$ but $x \neq O(x^2)$.
\end{example}
% Plot with x^2 x sqrt(x)
\begin{example}
  $\sin 2x = O(x)$ as $x \to 0$ since $|\sin 2x| \leq 2|x|\;\forall x$.
\end{example}
\begin{example}
  $f(x) = 2x^3 - 4x + 12 = O(x^3)$ as $x \to \infty$ since $\forall x > 1$
  \begin{align*}
    |2x^3 - 4x + 12| &\leq 2|x^3| + |-4x| + 12 \\
                     &\leq 6|x^3| + 4|x^3| + 12|x^3| \\
                     &\leq 22|x^3|
  \end{align*}
  So the definition is satisfied with $x_0 = 1 \text{ and } M = 22$.
\end{example}
\begin{definition}[Little-$o$ Notation]
  $f(x) = o(g(x))$ as $x \to x_0$ if \textbf{for every} $\varepsilon > 0, \exists \delta > 0 \text{ such that } \forall x \text{ with } 0 < |x - x_0| < \delta$ ($x$ sufficiently close to $x_0$) then $|f(x)| \leq \varepsilon |g(x)|$.

  If $g \neq 0$ is in the vicinity of $x_0$ but not necessarily at $x_0$ then an equivalent statement is that:
  \[
    \lim_{x \to x_0} \frac{f(x)}{g(x)} = 0
  \]
\end{definition}
\begin{remark}[Notation]
  Often written as $f(x) = o(g(x))$ or $\underline{o}(g(x))$ when handwritten to differentiate it from big O.
\end{remark}

$f(x) = o(g(x))$ loosely means that $f(x)$ is \textbf{much smaller} than $g(x)$ as $x \to x_0$. 
\begin{example}
 $x^2 = o(x)$ as $x \to 0$ as $\lim_{x \to 0} x^2/x = 0$
\end{example}
\begin{example}
  $\sqrt{x} = o(x)$ as $x \to \infty$ as $\lim_{x \to \infty} \sqrt{x}/x = 0$
\end{example}
\begin{remark}[Notes]
  \begin{itemize}
    \item $f(x) = o(g(x))$ is a stronger statement that $f(x) = O(g(x))$. 
      This is because little-o means that we are bounded by any multiple whereas big-O means were are bounded by a given multiple.

      So $f(x) = o(g(x)) \implies f(x) = O(g(x))$ but $f(x) = O(g(x)) \centernot\implies f(x) = o(g(x))$

      E.g. $f(x) = 2x = O(x)$ as $x \to 0$ but $f(x) \neq o(x)$ because $\lim_{x \to 0} 2x/x = 2$.
    \item Constants don't matter. If $f(x) = O(g(x))$ then $af(x) = O(g(x))$ and $f(x) = O(ag(x))$ for any non-zero constant $a$.
  \end{itemize} 
\end{remark}
Order parameters are useful to classify remainder terms before taking limits.
\begin{proposition}
  \[
    f(x_0 + h) = f(x_0) + hf'(x_0) + o(h) \text{ as } h\to0
  \]
\end{proposition}
\begin{proof}
  Suppose that we have a remainder/error term $\epsilon(h)$ before taking the limit in a derivative:
  \begin{align*}
    f(x_0 + h) - f(x_0) &= hf'(x_0) + \epsilon(h) \\
    \lim_{h \to 0} \left[\frac{f(x_0 + h) - f(x_0)}{h}\right] &= f'(x_0) + \lim_{h \to 0} \frac{\epsilon(h)}{h}
  \end{align*}
  From the definition of $f'(x)$ the final limit term vanishes so we have $\lim_{h \to 0} \epsilon(h)/h = 0$ and so $\epsilon(h) = o(h)$ as $h\to0$.
  This means that the error term is of order $o(h)$ so we can write:
  \[
    f(x_0 + h) = f(x_0) + hf'(x_0) + o(h) \text{ as } h\to0
  \]
\end{proof}
\end{document}
